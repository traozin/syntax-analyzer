package syntax.analyzer.model.grammar;

import java.util.Deque;
import lexical.analyzer.enums.TokenType;
import lexical.analyzer.model.Token;
import syntax.analyzer.model.exceptions.EOFNotExpectedException;
import syntax.analyzer.model.exceptions.SyntaxErrorException;
import syntax.analyzer.util.TokenUtil;
import syntax.analyzer.util.Terminals;
import static syntax.analyzer.util.Terminals.*;

/**
 *
 * @author Antonio Neto e Uellington Damasceno
 */
public class VarScope {

    public static void fullChecker(Deque<Token> tokens) throws EOFNotExpectedException, SyntaxErrorException {
        typedVariableScoped(tokens);
        if (TokenUtil.testLexameBeforeConsume(tokens, EQUALS)) {
            try {
                VarDeclaration.variableDeclaratorConsumer(tokens);
            } catch (SyntaxErrorException e) {
                EOFNotExpectedException.throwIfEmpty(tokens, DOT,
                        EQUALS,
                        OPEN_BRACKET);
                Token token = tokens.pop();
                EOFNotExpectedException.throwIfEmpty(tokens, IDENTIFIER,
                        LOCAL,
                        GLOBAL,
                        TRUE,
                        FALSE,
                        INT,
                        STRING,
                        REAL);
                Token nextToken = tokens.pop();
                EOFNotExpectedException.throwIfEmpty(tokens, DOT,
                        OPEN_PARENTHESES,
                        EQUALS,
                        CLOSE_BRACKET,
                        SEMICOLON,
                        OPEN_BRACKET);
                Token nextNextToken = tokens.peek();
                tokens.push(nextToken);
                tokens.push(token);
                if (nextNextToken.thisLexameIs(SEMICOLON.getVALUE())
                        || nextNextToken.thisLexameIs(OPEN_BRACKET.getVALUE())) {
                    TokenUtil.consumeExpectedTokenByLexame(tokens, EQUALS);
                    try {
                        VarScope.scopeModifierConsumer(tokens);
                        if (TokenUtil.testLexameBeforeConsume(tokens, OPEN_BRACKET)) {
                            Arrays.dimensionConsumer(tokens);
                        }
                    } catch (SyntaxErrorException ex) {
                        TokenUtil.consumerByType(tokens, TokenType.IDENTIFIER, Terminals.IDENTIFIER);
                        if (TokenUtil.testLexameBeforeConsume(tokens, OPEN_BRACKET)) {
                            Arrays.dimensionConsumer(tokens);
                        }
                    }
                } else {
                    VarUsage.fullChecker(tokens);
                }
            }

        } else {
            VarUsage.fullChecker(tokens);
        }
    }

    public static void scopeModifierConsumer(Deque<Token> tokens) throws EOFNotExpectedException, SyntaxErrorException {
        try {
            TokenUtil.consumerByLexame(tokens, GLOBAL);
        } catch (SyntaxErrorException e) {
            try {
                TokenUtil.consumerByLexame(tokens, LOCAL);
            } catch (SyntaxErrorException e1) {
                throw new SyntaxErrorException(tokens.peek().getLexame(), GLOBAL, LOCAL);
            }
        }
    }

    public static void typedVariableScoped(Deque<Token> tokens) throws EOFNotExpectedException, SyntaxErrorException {
        VarScope.scopeModifierConsumer(tokens);
        TokenUtil.consumeExpectedTokenByLexame(tokens, DOT);
        TokenUtil.consumerByType(tokens, TokenType.IDENTIFIER, Terminals.IDENTIFIER);
    }
}
